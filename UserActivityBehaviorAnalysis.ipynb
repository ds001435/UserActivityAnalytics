{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89df52f3-ab93-4044-874c-1b1ed4b789f2",
   "metadata": {},
   "source": [
    "# Streaming Music Service and it's User's Behavior Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09681d87-642c-44b3-82b4-d01fd1997e29",
   "metadata": {},
   "source": [
    "\n",
    "## Phase 1\n",
    "### 1. Consuming user activity data from Kafka and user metadata from S3\n",
    "### 2. Tranformation and enrichment of user activity data\n",
    "### 3. Partitioning and saving of transformed data in S3 for use by other downstream systems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d32d77-a4ea-4a5b-b936-3210404d9077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.streaming.{StreamingQueryListener, Trigger}\n",
       "import org.apache.spark.sql.streaming.StreamingQueryListener.QueryProgressEvent\n",
       "import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n",
       "import org.apache.spark.sql.{Column, DataFrame, SparkSession, streaming}\n",
       "import scala.concurrent.duration.DurationInt\n",
       "import org.apache.spark.sql.functions._\n",
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.streaming.{StreamingQueryListener, Trigger}\n",
    "import org.apache.spark.sql.streaming.StreamingQueryListener.QueryProgressEvent\n",
    "import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n",
    "import org.apache.spark.sql.{Column, DataFrame, SparkSession, streaming}\n",
    "import scala.concurrent.duration.DurationInt\n",
    "import org.apache.spark.sql.functions._\n",
    "import spark.implicits._\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae37b82-a650-4161-81f6-432db867173d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: org.apache.spark.sql.DataFrame = [key: string, value: string]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.access.key\", \"AKIA2OWOK4NJIL5XP7H7\")\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.secret.key\", \"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\")\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")\n",
    "spark.sql(\"set spark.sql.legacy.allowUntypedScalaUDF = true\")\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f0c147-d0b1-46ba-af43-a4ce1dda992a",
   "metadata": {},
   "source": [
    "\n",
    "### Schema definition of music listening activity event stream\n",
    "#### 1. User music listening activity has 5 columns\n",
    "##### a. eventID : ID of captured event. It is unique across complete dataset\n",
    "##### b. customerID : ID of user.\n",
    "##### c. songID : ID of song whcih user is listening.\n",
    "##### d. time : time of user activity.\n",
    "##### e. isMobile : platform used. i.e Mobile or Desktop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d15f1322-6e09-41c1-aeb2-6ede48c962d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- eventID: integer (nullable = true)\n",
      " |-- customerID: integer (nullable = true)\n",
      " |-- songID: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- isMobile: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "activityEventsSchema: org.apache.spark.sql.types.StructType = StructType(StructField(eventID,IntegerType,true), StructField(customerID,IntegerType,true), StructField(songID,StringType,true), StructField(time,StringType,true), StructField(isMobile,IntegerType,true))\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " val activityEventsSchema =  new StructType()\n",
    "        .add(\"eventID\", IntegerType, nullable=true)\n",
    "        .add(\"customerID\", IntegerType, nullable=true)\n",
    "        .add(\"songID\", StringType, nullable=true)\n",
    "        .add(\"time\", StringType, nullable=true)\n",
    "        .add(\"isMobile\", IntegerType, nullable=true)\n",
    "\n",
    "activityEventsSchema.printTreeString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa66b6d3-9614-49ef-a7fd-30e7240db91e",
   "metadata": {},
   "source": [
    "\n",
    "### Reading data from realtime pipeline\n",
    "#### 1. Reading user activity stream from kafka\n",
    "#### 2. Parsing Json\n",
    "#### 3. Creation of spark dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77606546-39f6-4a9a-825e-79a92e784f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- eventID: integer (nullable = true)\n",
      " |-- customerID: integer (nullable = true)\n",
      " |-- songID: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- isMobile: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "eventsDF: org.apache.spark.sql.DataFrame = [eventID: int, customerID: int ... 3 more fields]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   \n",
    "    val eventsDF = spark.readStream\n",
    "      .format(\"kafka\")\n",
    "      .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "      .option(\"subscribe\", \"useractivityevents\")\n",
    "      .option(\"startingOffsets\", \"latest\")\n",
    "      .load()\n",
    "      .select($\"value\" cast \"string\" as \"json\")\n",
    "      .select(from_json($\"json\", activityEventsSchema) as \"data\")\n",
    "      .select(col(\"data.*\"))   \n",
    "\n",
    "eventsDF.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d750215-93f4-458e-b073-5e6d8f63ca4f",
   "metadata": {},
   "source": [
    "\n",
    "### Reading user metadata from S3\n",
    "#### 1. User metadata is used to enrich streaming data. Is is present in s3 in json format \n",
    "#### 2. It has 4 columns\n",
    "##### a. customerID : ID of customer. This field will be used for joining with streaming data\n",
    "##### b. Gender : Gender of User. i.e Male or Female\n",
    "##### c. subscriptionStatus : Is Subsription Active or Expired ?\n",
    "##### d. subscriptionType : Level of Subscription i.e Free, Gold or Premium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312da9a2-03e6-407a-b56b-260d22a8c9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerID: long (nullable = true)\n",
      " |-- gender: long (nullable = true)\n",
      " |-- subscriptionStatus: long (nullable = true)\n",
      " |-- subscriptionType: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "customerInfo: org.apache.spark.sql.DataFrame = [customerID: bigint, gender: bigint ... 2 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val customerInfo = spark.read.json(\"s3a://ds-mum-sparkdemoproject/usermetadata/user.json\")\n",
    "\n",
    "customerInfo.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb85cf57-cc88-404a-8939-444493a41739",
   "metadata": {},
   "source": [
    "\n",
    "### User metadata sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c81f6e62-6a71-4f63-b978-5c50712e20bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------------------+----------------+\n",
      "|customerID|gender|subscriptionStatus|subscriptionType|\n",
      "+----------+------+------------------+----------------+\n",
      "|         0|     0|                 1|               1|\n",
      "|         1|     0|                 1|               1|\n",
      "|         2|     0|                 1|               0|\n",
      "|         3|     0|                 1|               1|\n",
      "|         4|     0|                 1|               0|\n",
      "+----------+------+------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customerInfo.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15095a2-d410-46c0-8557-70c647c19ca3",
   "metadata": {},
   "source": [
    "\n",
    "### Transformation of user activity data\n",
    "#### 1. Addition of phase of day i.e Morning,Afternoon,Evening,Night based on user activity at particular hour of day\n",
    "#### 2. Addition of year,month,day,hour for partitioning purpose\n",
    "#### 3. Updating deviceType and level of subscription id's with meaningful literals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f813559-8c5b-410a-a32d-c7b11095e5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- eventID: integer (nullable = true)\n",
      " |-- customerID: integer (nullable = true)\n",
      " |-- songID: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- isMobile: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- phaseOfDay: string (nullable = true)\n",
      " |-- deviceType: string (nullable = false)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transformedDF: org.apache.spark.sql.DataFrame = [eventID: int, customerID: int ... 9 more fields]\n",
       "updatesubScriptionValue: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$3930/0x000000084172d840@1bcfab3e,StringType,List(),None,None,true,true)\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "val transformedDF = eventsDF\n",
    "      .select(col(\"eventID\"), col(\"customerID\"), col(\"songID\"), col(\"time\"), col(\"isMobile\"),\n",
    "        hour(col(\"time\")).alias(\"hour\"),\n",
    "        when((hour(col(\"time\")) < 4) || (hour(col(\"time\")) >= 21), lit(\"Night\"))\n",
    "          .when((hour(col(\"time\")) >= 4) && (hour(col(\"time\")) < 11), lit(\"Morning\"))\n",
    "          .when((hour(col(\"time\")) >= 11) && (hour(col(\"time\")) < 16), lit(\"Afternoon\"))\n",
    "          .when((hour(col(\"time\")) >= 16) && (hour(col(\"time\")) < 21), lit(\"Evening\"))\n",
    "          .alias(\"phaseOfDay\"),\n",
    "        when(col(\"isMobile\") === 1, lit(\"mobile\")).otherwise(lit(\"desktop\")).alias(\"deviceType\")\n",
    "      ).withColumn(\"year\",year(col(\"time\")))\n",
    "      .withColumn(\"month\",month(col(\"time\")))\n",
    "      .withColumn(\"day\",dayofmonth(col(\"time\")))\n",
    "      .withColumn(\"hour\",hour(col(\"time\")))\n",
    "    val updatesubScriptionValue = udf((level: Long) => {\n",
    "      val map:Map[Long, String] = Map(0L -> \"Free\", 1L -> \"Gold\", 2L -> \"Premium\")\n",
    "      map.get(level).get\n",
    "    },StringType)\n",
    "\n",
    "transformedDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e37430d-2733-4981-853d-cd671cd0e813",
   "metadata": {},
   "source": [
    "\n",
    "### Joining user activity stream with customer metadata DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24aa779b-f6fe-431f-a3e5-5a0e5d18b704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerID: integer (nullable = true)\n",
      " |-- eventID: integer (nullable = true)\n",
      " |-- songID: string (nullable = true)\n",
      " |-- isMobile: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- phaseOfDay: string (nullable = true)\n",
      " |-- deviceType: string (nullable = false)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- subscriptionStatus: string (nullable = false)\n",
      " |-- subscriptionType: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "joinedDF: org.apache.spark.sql.DataFrame = [customerID: int, eventID: int ... 11 more fields]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val joinedDF = transformedDF.join(customerInfo, Seq(\"customerID\"), \"inner\")\n",
    "      .withColumn(\"gender\", when((col(\"gender\") === 1), \"Female\").otherwise(\"Male\"))\n",
    "      .withColumn(\"subscriptionStatus\", when((col(\"subscriptionStatus\") === 1), \"Active\").otherwise(\"Expired\"))\n",
    "      .withColumn(\"subscriptionType\", updatesubScriptionValue(col(\"subscriptionType\")))\n",
    "      .drop(\"time\")\n",
    "\n",
    "joinedDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8dc456-3df3-42b8-855a-fed2c92b6fa0",
   "metadata": {},
   "source": [
    "\n",
    "### Writing tranformed data to S3 for use by other downstream systems\n",
    "#### 1. Data is partitioned by deviceType (Mobile or Desktop), year,month,day,hour\n",
    "#### 2. Data is saved in json format\n",
    "#### 3. A Query Monitoring interface is also added to get progress updates of streaming batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c45fcc43-1187-45fe-a72d-51d50e97af22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numInputRows: 0\n",
      "processedRowsPerSecond: 0.0\n",
      "numInputRows: 100\n",
      "processedRowsPerSecond: 4.855075981939117\n",
      "numInputRows: 100\n",
      "processedRowsPerSecond: 5.430650591940914\n",
      "numInputRows: 100\n",
      "processedRowsPerSecond: 5.372589050663515\n",
      "numInputRows: 100\n",
      "processedRowsPerSecond: 5.267871253226571\n",
      "numInputRows: 100\n",
      "processedRowsPerSecond: 5.339598462195642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined class MonitorListener\n",
       "partitionColumns: Seq[String] = List(deviceType, year, month, day, hour)\n",
       "res7: Boolean = false\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numInputRows: 0\n",
      "processedRowsPerSecond: 0.0\n",
      "numInputRows: 0\n",
      "processedRowsPerSecond: 0.0\n",
      "numInputRows: 0\n",
      "processedRowsPerSecond: 0.0\n"
     ]
    }
   ],
   "source": [
    " class MonitorListener extends StreamingQueryListener {\n",
    "\n",
    "    override def onQueryStarted(event: StreamingQueryListener.QueryStartedEvent): Unit = { }\n",
    "\n",
    "    override def onQueryProgress(event: QueryProgressEvent): Unit = {\n",
    "      println(s\"\"\"numInputRows: ${event.progress.numInputRows}\"\"\")\n",
    "      println(s\"\"\"processedRowsPerSecond: ${event.progress.processedRowsPerSecond}\"\"\")\n",
    "    }\n",
    "\n",
    "    override def onQueryTerminated(event: StreamingQueryListener.QueryTerminatedEvent): Unit = { }\n",
    "  }\n",
    "\n",
    "spark.streams.addListener(new MonitorListener)\n",
    "\n",
    "val partitionColumns = Seq(\"deviceType\",\"year\",\"month\",\"day\",\"hour\")\n",
    "    joinedDF.coalesce(1)\n",
    "      .writeStream\n",
    "      .partitionBy(partitionColumns:_*)\n",
    "      .format(\"json\")\n",
    "      .option(\"path\", \"s3a://ds-mum-sparkdemoproject/UserBehaviorAnalysis/\")\n",
    "      .option(\"checkpointLocation\", \"/tmp/checkpoint-c1\")\n",
    "      .start().awaitTermination(2 * 60 * 1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0880b70-eafc-463e-9d35-b2fd3b442a06",
   "metadata": {},
   "source": [
    "\n",
    "## Phase 2\n",
    "### 1. Consuming transformed and enriched user activity data from S3\n",
    "### 2. Running SQL queries to get various insights on user behavior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b83ce15-978a-468c-9f1b-694e8b08f321",
   "metadata": {},
   "source": [
    "\n",
    "### Reading data from S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55004838-28d9-44f4-9518-749d23805d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://4dee036fca3c:4040\n",
       "SparkContext available as 'sc' (version = 3.2.1, master = local[*], app id = local-1651993671185)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.streaming.{StreamingQueryListener, Trigger}\n",
       "import org.apache.spark.sql.streaming.StreamingQueryListener.QueryProgressEvent\n",
       "import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n",
       "import org.apache.spark.sql.{Column, DataFrame, SparkSession, streaming}\n",
       "import scala.concurrent.duration.DurationInt\n",
       "import org.apache.spark.sql.functions._\n",
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.streaming.{StreamingQueryListener, Trigger}\n",
    "import org.apache.spark.sql.streaming.StreamingQueryListener.QueryProgressEvent\n",
    "import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n",
    "import org.apache.spark.sql.{Column, DataFrame, SparkSession, streaming}\n",
    "import scala.concurrent.duration.DurationInt\n",
    "import org.apache.spark.sql.functions._\n",
    "import spark.implicits._\n",
    "\n",
    "\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.access.key\", \"AKIA2OWOK4NJIL5XP7H7\")\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.secret.key\", \"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\")\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ece7bce-58cc-4722-b60c-933363408ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+------+--------+----------+------+------------------+----------------+----------+----+-----+---+----+\n",
      "|customerID|eventID|gender|isMobile|phaseOfDay|songID|subscriptionStatus|subscriptionType|deviceType|year|month|day|hour|\n",
      "+----------+-------+------+--------+----------+------+------------------+----------------+----------+----+-----+---+----+\n",
      "|      2265|    120|Female|       0| Afternoon|   703|            Active|            Free|   desktop|2014|   12|  7|  12|\n",
      "|       412|    171|Female|       0| Afternoon|   101|            Active|            Free|   desktop|2014|   12|  7|  12|\n",
      "|      3704|    140|Female|       1|   Morning|   156|            Active|            Free|    mobile|2014|   10| 25|   9|\n",
      "|        62|    153|Female|       1|   Morning|  1348|           Expired|            Free|    mobile|2014|   10| 25|   9|\n",
      "|      3572|    232|  Male|       0|   Morning|     4|            Active|            Gold|   desktop|2014|   10|  7|   4|\n",
      "|      4867|    296|  Male|       0|   Morning|    35|            Active|            Free|   desktop|2014|   10|  7|   4|\n",
      "|      1034|    447|  Male|       1| Afternoon|  1057|           Expired|         Premium|    mobile|2014|   10| 28|  11|\n",
      "|      1062|    272|Female|       1| Afternoon|    32|            Active|         Premium|    mobile|2014|   11| 13|  13|\n",
      "|       148|    152|Female|       1| Afternoon|   218|            Active|         Premium|    mobile|2014|   11|  4|  13|\n",
      "|      1540|    366|Female|       1| Afternoon|    57|            Active|         Premium|    mobile|2014|   10| 21|  12|\n",
      "+----------+-------+------+--------+----------+------+------------------+----------------+----------+----+-----+---+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataDF: org.apache.spark.sql.DataFrame = [customerID: bigint, eventID: bigint ... 11 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val dataDF = spark.read.json(\"s3a://ds-mum-sparkdemoproject/UserBehaviorAnalysis\")\n",
    "\n",
    "dataDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e32042a4-3aac-4b6a-aafa-46c0779ad855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Long = 500\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff7afa-95af-4405-9be0-d536b4751b39",
   "metadata": {},
   "source": [
    "\n",
    "### Registering as table to use in various SQL queries and printing sample data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9188b047-7a2c-48c4-8f09-ad9a1d3f16de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+------+--------+----------+------+------------------+----------------+----------+----+-----+---+----+\n",
      "|customerID|eventID|gender|isMobile|phaseOfDay|songID|subscriptionStatus|subscriptionType|deviceType|year|month|day|hour|\n",
      "+----------+-------+------+--------+----------+------+------------------+----------------+----------+----+-----+---+----+\n",
      "|      2265|    120|Female|       0| Afternoon|   703|            Active|            Free|   desktop|2014|   12|  7|  12|\n",
      "|       412|    171|Female|       0| Afternoon|   101|            Active|            Free|   desktop|2014|   12|  7|  12|\n",
      "|      3704|    140|Female|       1|   Morning|   156|            Active|            Free|    mobile|2014|   10| 25|   9|\n",
      "|        62|    153|Female|       1|   Morning|  1348|           Expired|            Free|    mobile|2014|   10| 25|   9|\n",
      "|      3572|    232|  Male|       0|   Morning|     4|            Active|            Gold|   desktop|2014|   10|  7|   4|\n",
      "|      4867|    296|  Male|       0|   Morning|    35|            Active|            Free|   desktop|2014|   10|  7|   4|\n",
      "|      1034|    447|  Male|       1| Afternoon|  1057|           Expired|         Premium|    mobile|2014|   10| 28|  11|\n",
      "|      1062|    272|Female|       1| Afternoon|    32|            Active|         Premium|    mobile|2014|   11| 13|  13|\n",
      "|       148|    152|Female|       1| Afternoon|   218|            Active|         Premium|    mobile|2014|   11|  4|  13|\n",
      "|      1540|    366|Female|       1| Afternoon|    57|            Active|         Premium|    mobile|2014|   10| 21|  12|\n",
      "|      1152|    497|Female|       1|   Morning|  1377|            Active|         Premium|    mobile|2014|   10|  7|   8|\n",
      "|      1093|    329|  Male|       1| Afternoon|   123|           Expired|         Premium|    mobile|2014|   11| 30|  14|\n",
      "|      3652|    355|Female|       1|   Evening|   170|           Expired|         Premium|    mobile|2014|   10|  5|  20|\n",
      "|      2940|    458|Female|       1|   Morning|   238|            Active|         Premium|    mobile|2014|   10| 15|   7|\n",
      "|       595|    136|Female|       1| Afternoon|    70|            Active|         Premium|    mobile|2014|   11|  6|  15|\n",
      "|      4999|    417|Female|       0| Afternoon|     3|            Active|         Premium|   desktop|2014|   10| 11|  11|\n",
      "|      1251|    254|Female|       0| Afternoon|  1100|            Active|            Free|   desktop|2014|   11|  2|  12|\n",
      "|      1347|    292|Female|       1| Afternoon|  1271|            Active|            Free|    mobile|2014|   11| 17|  13|\n",
      "|      4554|    410|Female|       0| Afternoon|  1000|            Active|            Free|   desktop|2014|   10| 13|  13|\n",
      "|      2584|    442|Female|       0| Afternoon|  1490|            Active|            Free|   desktop|2014|   12| 24|  12|\n",
      "+----------+-------+------+--------+----------+------+------------------+----------------+----------+----+-----+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF.createOrReplaceTempView(\"UserTable\")\n",
    "\n",
    "spark.sql(\"\"\"SELECT * FROM UserTable\"\"\").show(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb806037-2c6a-499e-87d1-2013821d41df",
   "metadata": {},
   "source": [
    "\n",
    "### Percentage of Mobile and Desktop users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c1d00ec-6c15-453a-8b7e-e2a3ad020365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|deviceType|        percentage|\n",
      "+----------+------------------+\n",
      "|   desktop| 43.42984409799555|\n",
      "|    mobile|60.356347438752785|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select deviceType,count(distinct(customerID))*100/(select count(distinct(customerID)) from usertable) as percentage from usertable group by deviceType \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9348179c-239c-4c32-9a5b-e314c269952b",
   "metadata": {},
   "source": [
    "### Distribution of users listening to music during different phase of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78aa96f3-905b-4ebe-93fe-5226a77d603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|phaseOfDay|percentage|\n",
      "+----------+----------+\n",
      "|   Evening|      21.6|\n",
      "|   Morning|      27.6|\n",
      "| Afternoon|      22.8|\n",
      "|     Night|      28.0|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select phaseOfDay,count(*) * 100/(select count(*) from usertable) as percentage from usertable group by phaseofday \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae014d-04dc-486e-8835-642d3eebedf2",
   "metadata": {},
   "source": [
    "### Distribution of Subscription Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e1c219-4147-4dea-9815-5cc8dfdd678b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+\n",
      "|subscriptionType|        percentage|\n",
      "+----------------+------------------+\n",
      "|            Free|58.797327394209354|\n",
      "|            Gold| 28.50779510022272|\n",
      "|         Premium|12.694877505567929|\n",
      "+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select subscriptionType,count(distinct(customerID))*100/(select count(distinct(customerID)) from usertable) as percentage from usertable group by subscriptionType order by percentage desc \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c009f98-433b-4c2b-8946-e15484fb1810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
